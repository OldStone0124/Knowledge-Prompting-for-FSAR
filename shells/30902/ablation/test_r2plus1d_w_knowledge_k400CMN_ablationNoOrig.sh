cd few-shot-video-classification/ && CUDA_VISIBLE_DEVICES=1 python tsl_fsv_w_knowledge.py --test_video_path  /media/nvme1/linhanxi/data/k400/k400_CMNsplit/ \
--manual_seed 10 \
--test_list_path data/kinetics100/data_splits/meta_test_filtered.txt \
--dataset kinetics100 \
--train_crop random \
--n_samples_for_each_video 10 \
--n_val_samples 10 \
--clip_model r2plus1d_w_knowledge \
--clip_model_depth 34 \
--n_threads 4 \
--result_path /media/hdd/sda1/linhanxi/exp/few-shot-vid-cls/test_kinetics_w_knowledge/v0.3_ablation_origBugfix_drop0.9_save4_5w5s_metaTest_32frms_TSM1_Sparse_PartV2.1 \
--shot 5 \
--test_way 5 \
--query 5 \
--resume_path /media/hdd/sda1/linhanxi/exp/few-shot-vid-cls/finetune_kinetics/w_knowledge/v0.3_clsBugFix_embedOrig_dropout0.9_ablation_origBugfix_sparseSample_TSM1_32frms_PartV2/save_4.pth \
--emb_dim 512 \
--batch_size 64 \
--lr 0.01 \
--nepoch 10 \
--CLIP_visual_fea_reg "/home/linhanxi/home_data/kinetics/fea_clip_ViT-B-16_unfolded_32frms/*" \
--proposals_fea_pth /media/hdd/sda1/linhanxi/data/CLIP_related/action_knowledge/action_knowledge/KineticsCMN/proposal_fea_cachePartV2.1.pt \
--CLIP_visual_arch "ViT-B/16"  --clip_visfea_sampleNum 32 --n_finetune_classes 64 --is_w_knowledge \
--is_amp --this_launch_script $0 --ablation_removeOrig  --print_freq 200 --sample_mode sparse --temporal_modeling TSM1 #--CLIP_visual_fea_preload